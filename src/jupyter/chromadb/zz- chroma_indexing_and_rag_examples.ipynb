{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjlwUPWugM37"
   },
   "source": [
    "# Use ChromaDocumentStore with Haystack\n",
    "\n",
    "https://docs.haystack.deepset.ai/docs/chromadocumentstore\n",
    "\n",
    "WORKING (chromadb2 env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "znSRD-hO2doM"
   },
   "outputs": [],
   "source": [
    "# Install the Chroma integration, Haystack will come as a dependency\n",
    "# !pip install -U chroma-haystack \"huggingface_hub>=0.22.0\"\n",
    "\n",
    "#!pip install chroma-haystack\n",
    "#!pip install torch torchaudio torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gt_XhGXBgU-I"
   },
   "source": [
    "## Indexing Pipeline: preprocess, split and index documents\n",
    "In this section, we will index documents into a Chroma DB collection by building a Haystack indexing pipeline. Here, we are indexing documents from the [VIM User Manuel](https://vimhelp.org/) into the Haystack `ChromaDocumentStore`.\n",
    "\n",
    " We have the `.txt` files for these pages in the examples folder for the `ChromaDocumentStore`, so we are using the [`TextFileToDocument`](https://docs.haystack.deepset.ai/v2.0/docs/textfiletodocument) and [`DocumentWriter`](https://docs.haystack.deepset.ai/v2.0/docs/documentwriter) components to build this indexing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.preprocessors import DocumentSplitter, DocumentCleaner\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "from haystack_integrations.document_stores.chroma import ChromaDocumentStore\n",
    "from haystack import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print  # https://rich.readthedocs.io/en/stable/markup.html#console-markup\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.highlighter import RegexHighlighter\n",
    "from rich.theme import Theme\n",
    "from rich.text import Text\n",
    "from rich.padding import Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_list = [\n",
    "    r\"(?i)(?P<bankother>phone|bank shot|bank of the|banked)\",\n",
    "    r\"(?i)(?P<bank>bank|boa|teller|deposit|vault|account)\",\n",
    "\n",
    "    r\"(?i)(?P<boardother>back board|board of direct|board the)\",\n",
    "    r\"(?i)(?P<board>board|plank|timber|2x4|wood supplies)\",\n",
    "\n",
    "    r\"(?i)(?P<flying>fly over|pilot|navigation|boeing|747|landing)\",\n",
    "    r\"(?i)(?P<cool>fly sister|cool)\",\n",
    "    r\"(?i)(?P<fly>fly)\",\n",
    "]\n",
    "\n",
    "class MyHighlighter(RegexHighlighter):\n",
    "    \"\"\"Apply style to anything that looks like an email.\"\"\"\n",
    "    base_style = \"example.\"\n",
    "    highlights = hl_list\n",
    "\n",
    "my_hl = MyHighlighter()\n",
    "\n",
    "theme = Theme(\n",
    "    {\"example.bankother\": \"bold green\",\n",
    "     \"example.bank\": \"bold bright_green\",\n",
    "\n",
    "     \"example.boardother\": \"bold blue\",\n",
    "     \"example.board\": \"bold bright_blue\",\n",
    "\n",
    "     \"example.flying\": \"bold red\",\n",
    "     \"example.cool\": \"bold bright_magenta\",\n",
    "     \"example.fly\": \"bold bright_red\",\n",
    "     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Highlighting demo: 'My <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">bank</span> is not <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">BoA</span>, but is on the <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">bank</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> of the</span> river. Sometimes I <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">fly</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> over</span> the <span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold\">board</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> of </span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">direct</span>ors to look <span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">cool</span>.'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Highlighting demo: 'My \u001b[1;92mbank\u001b[0m is not \u001b[1;92mBoA\u001b[0m, but is on the \u001b[1;92mbank\u001b[0m\u001b[1;32m of the\u001b[0m river. Sometimes I \u001b[1;91mfly\u001b[0m\u001b[1;31m over\u001b[0m the \u001b[1;94mboa\u001b[0m\u001b[1;94mrd\u001b[0m\u001b[1;34m of \u001b[0m\n",
       "\u001b[1;34mdirect\u001b[0mors to look \u001b[1;95mcool\u001b[0m.'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console = Console(highlighter=my_hl, theme=theme)\n",
    "console.print(\"Highlighting demo: 'My bank is not BoA, but is on the bank of the river. Sometimes I fly over the board of directors to look cool.'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Torchy?? <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Torchy?? \u001b[1;3;31mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Torchy?? [bold red]{torch.cuda.is_available()}[/]\")\n",
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'../data/test-paragraphs.txt'</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'../data/test-paragraphs.txt'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# file_paths = [\"data\" / Path(name) for name in os.listdir(\"data\")]\n",
    "from pathlib import Path\n",
    "data_dir = \"../data/\"\n",
    "text_files = list(Path(data_dir).glob(\"**/*.txt\"))\n",
    "print(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Doc store count at start: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Doc store count at start: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store = ChromaDocumentStore()\n",
    "print(f\"Doc store count at start: {document_store.count_documents()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove repeated substrings to get rid of headers/footers\n",
    "cleaner = DocumentCleaner(remove_repeated_substrings=True)\n",
    "# Since jina-v2 can handle 8192 tokens, 500 words seems like a safe chunk size\n",
    "# splitter = DocumentSplitter(split_by=\"word\", split_length=30, split_overlap=5)\n",
    "splitter = DocumentSplitter(split_by=\"sentence\", split_length=1, split_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = Document()\n",
    "split_docs = splitter.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "document_embedder = SentenceTransformersDocumentEmbedder(model=embedding_model)\n",
    "document_writer = DocumentWriter(document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing = Pipeline()\n",
    "indexing.add_component(\"converter\", TextFileToDocument())\n",
    "indexing.add_component(instance=cleaner, name=\"document_cleaner\")\n",
    "indexing.add_component(instance=splitter, name=\"document_splitter\")\n",
    "indexing.add_component(instance=document_embedder, name=\"document_embedder\")\n",
    "indexing.add_component(instance=document_writer, name=\"document_writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fd39a726bc0>\n",
       "🚅 Components\n",
       "  - converter: TextFileToDocument\n",
       "  - document_cleaner: DocumentCleaner\n",
       "  - document_splitter: DocumentSplitter\n",
       "  - document_embedder: SentenceTransformersDocumentEmbedder\n",
       "  - document_writer: DocumentWriter\n",
       "🛤️ Connections\n",
       "  - converter.documents -> document_cleaner.documents (List[Document])\n",
       "  - document_cleaner.documents -> document_splitter.documents (List[Document])\n",
       "  - document_splitter.documents -> document_embedder.documents (List[Document])\n",
       "  - document_embedder.documents -> document_writer.documents (List[Document])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexing.connect(\"converter\", \"document_cleaner\")\n",
    "indexing.connect(\"document_cleaner\", \"document_splitter\")\n",
    "indexing.connect(\"document_splitter\", \"document_embedder\")\n",
    "indexing.connect(\"document_embedder\", \"document_writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822eb1de34a3403d88f701fe8e67f8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'document_writer': {'documents_written': 25}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexing.run({\"converter\": {\"sources\": text_files}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Doc store count <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">AFTER INDEXING: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">25</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Doc store count \u001b[1;31mAFTER INDEXING: \u001b[0m\u001b[1;31m25\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Doc store count [red bold]AFTER INDEXING: {document_store.count_documents()}[/]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline components\n",
    "from haystack_integrations.components.retrievers.chroma import ChromaQueryTextRetriever\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "\n",
    "retriever = ChromaQueryTextRetriever(document_store=document_store, top_k=3)\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=embedding_model)\n",
    "text_embedder.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_pipeline = Pipeline()\n",
    "query_pipeline.add_component(\"retriever\", retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# simpple sanity check that we can embed a query outside the pipeline \n",
    "# todo -- confirm pipeline is in fact embedding the query \"magically\" in the current setup\n",
    "query_embedding = text_embedder.run(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(f\"Example embedding (first 10):  {query_embedding['embedding'][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"How many languages are there?\"\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_pipeline.run({\"retriever\": {\"query\": q, \"top_k\": k}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in result[\"retriever\"][\"documents\"]:\n",
    "#     print(f\"Doc: {doc.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(table_title, results, show_lines=True, ):\n",
    "    table = Table(title=table_title, show_lines=show_lines, highlight=True)\n",
    "    # table.add_column(\"id\", style=\"blue\", )  # no_wrap=True\n",
    "    table.add_column(\"Score\", style=\"blue\", )\n",
    "    table.add_column(\"text\")  # no_wrap=True\n",
    "    for d in results[\"retriever\"][\"documents\"]:\n",
    "        #pretty_content = Pretty(d.content.strip())\n",
    "        table.add_row(\"{:.2f}\".format(d.score), d.content.strip())\n",
    "\n",
    "    console.print(table)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                          Embedding model: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; font-style: italic\">sentence-transformers/all-MiniLM-L6-v2</span><span style=\"font-style: italic\">                           </span>\n",
       "<span style=\"font-style: italic\">                                    Query: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; font-style: italic\">How many languages are there?</span><span style=\"font-style: italic\">                                    </span>\n",
       "┏━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Score </span>┃<span style=\"font-weight: bold\"> text                                                                                             </span>┃\n",
       "┡━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #000080; text-decoration-color: #000080\"> 1.94  </span>│ Some colleagues suggested the shopper could have chosen different <span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold\">timber</span>.                        │\n",
       "├───────┼──────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #000080; text-decoration-color: #000080\"> 1.97  </span>│ Several members of the <span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold\">board</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> of direct</span>ors ignored it.                                            │\n",
       "├───────┼──────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #000080; text-decoration-color: #000080\"> 1.98  </span>│ Then she thought about Bill Murray, and whether he was sitting on the <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">bank</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> of the</span> river fishing. │\n",
       "├───────┼──────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #000080; text-decoration-color: #000080\"> 2.00  </span>│ Shaking his head, the witness decided to <span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold\">board</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> the</span> train.                                        │\n",
       "├───────┼──────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #000080; text-decoration-color: #000080\"> 2.01  </span>│ Most witnesses thought it was a <span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold\">plank</span> prank.                                                     │\n",
       "└───────┴──────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                          Embedding model: \u001b[0m\u001b[1;3;34msentence-transformers/all-MiniLM-L6-v2\u001b[0m\u001b[3m                           \u001b[0m\n",
       "\u001b[3m                                    Query: \u001b[0m\u001b[1;3;34mHow many languages are there?\u001b[0m\u001b[3m                                    \u001b[0m\n",
       "┏━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mScore\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtext                                                                                            \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[34m \u001b[0m\u001b[34m1.94 \u001b[0m\u001b[34m \u001b[0m│ Some colleagues suggested the shopper could have chosen different \u001b[1;94mtimber\u001b[0m.                        │\n",
       "├───────┼──────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[34m \u001b[0m\u001b[34m1.97 \u001b[0m\u001b[34m \u001b[0m│ Several members of the \u001b[1;94mboa\u001b[0m\u001b[1;94mrd\u001b[0m\u001b[1;34m of direct\u001b[0mors ignored it.                                            │\n",
       "├───────┼──────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[34m \u001b[0m\u001b[34m1.98 \u001b[0m\u001b[34m \u001b[0m│ Then she thought about Bill Murray, and whether he was sitting on the \u001b[1;92mbank\u001b[0m\u001b[1;32m of the\u001b[0m river fishing. │\n",
       "├───────┼──────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[34m \u001b[0m\u001b[34m2.00 \u001b[0m\u001b[34m \u001b[0m│ Shaking his head, the witness decided to \u001b[1;94mboa\u001b[0m\u001b[1;94mrd\u001b[0m\u001b[1;34m the\u001b[0m train.                                        │\n",
       "├───────┼──────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[34m \u001b[0m\u001b[34m2.01 \u001b[0m\u001b[34m \u001b[0m│ Most witnesses thought it was a \u001b[1;94mplank\u001b[0m prank.                                                     │\n",
       "└───────┴──────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = f\"Embedding model: [bold blue]{embedding_model}[/] \\nQuery: [bold blue]{q}[/]\"\n",
    "display_results(title, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44cRT55agw2e",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Query Pipeline: build retrieval-augmented generation (RAG) pipelines\n",
    "\n",
    "Once we have documents in the `ChromaDocumentStore`, we can use the accompanying Chroma retrievers to build a query pipeline. The query pipeline below is a simple retrieval-augmented generation (RAG) pipeline that uses Chroma's [query API](https://docs.trychroma.com/usage-guide#querying-a-collection).\n",
    "\n",
    "You can change the idnexing pipeline and query pipelines here for embedding search by using one of the [`Haystack Embedders`](https://docs.haystack.deepset.ai/v2.0/docs/embedders) accompanied by the  `ChromaEmbeddingRetriever`.\n",
    "\n",
    "\n",
    "In this example we are using:\n",
    "- The `HuggingFaceTGIGenerator` with the Mistral-7B-Instruct-v0.1. (You will need a Hugging Face token to use this model). You can repleace this with any of the other [`Generators`](https://docs.haystack.deepset.ai/v2.0/docs/generators)\n",
    "- The `PromptBuilder` which holds the prompt template. You can adjust this to a prompt of your choice\n",
    "- The `ChromaQueryRetriver` which expects a list of queries and retieves the `top_k` most relevant documents from your Chroma collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGGApIR3pllW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "hfat = \"HF_API_TOKEN\"\n",
    "if hfat in os.environ:\n",
    "    print(\"---------- Found hugging face token in environ, no need to prompt\")\n",
    "    hf_token = os.environ[\"HF_API_TOKEN\"]\n",
    "else:\n",
    "    print(\"++++++++++ Found hugging face token NOT in environ, need to prompt...\")\n",
    "    hf_token = getpass(\"Enter Hugging Face API key:\")\n",
    "    os.environ[\"HF_API_TOKEN\"] = hf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQJTPYNreNV-"
   },
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "prompt = \"\"\"\n",
    "Answer the query based on the provided context.\n",
    "If the context does not contain the answer, say 'Answer not found'.\n",
    "Context:\n",
    "{% for doc in documents %}\n",
    "  {{ doc.content }}\n",
    "{% endfor %}\n",
    "query: {{query}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_builder = PromptBuilder(template=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQJTPYNreNV-"
   },
   "outputs": [],
   "source": [
    "from haystack_integrations.components.retrievers.chroma import ChromaQueryTextRetriever\n",
    "from haystack.components.generators import HuggingFaceTGIGenerator\n",
    "from haystack.utils import Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQJTPYNreNV-"
   },
   "outputs": [],
   "source": [
    "stoken = Secret.from_token(hf_token)\n",
    "# client = HuggingFaceTGIGenerator(model=\"mistralai/Mistral-7B-v0.1\", token=Secret.from_token(hf_token)\n",
    "client = HuggingFaceTGIGenerator(model=\"mistralai/Mistral-7B-Instruct-v0.2\", token=stoken)\n",
    "# HuggingFaceTGIGenerator(model=\"mistralai/Mistral-7B-v0.1\", token=Secret.from_token("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQJTPYNreNV-"
   },
   "outputs": [],
   "source": [
    "client.warm_up()\n",
    "response = client.run(\"What's Natural Language Processing?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQJTPYNreNV-"
   },
   "outputs": [],
   "source": [
    "llm = HuggingFaceTGIGenerator(model=\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "llm.warm_up()\n",
    "retriever = ChromaQueryTextRetriever(document_store)\n",
    "\n",
    "querying = Pipeline()\n",
    "querying.add_component(\"retriever\", retriever)\n",
    "querying.add_component(\"prompt_builder\", prompt_builder)\n",
    "querying.add_component(\"llm\", llm)\n",
    "\n",
    "querying.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "querying.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8jcmcdqrGu1"
   },
   "outputs": [],
   "source": [
    "query = \"What is the Revenue Capacity for jacksonville beach?\"\n",
    "query = \"How is annual enrollment assessed in Jax Beach schools?\"\n",
    "# NOTE / TODO: typo our outdated synax from example?? --> \"retriever\": {\"queries\": [query]... is wrong/broken\n",
    "results = querying.run({\"retriever\": {\"query\": query, \"top_k\": 3},\n",
    "                        \"prompt_builder\": {\"query\": query},\n",
    "                        \"llm\":{\"generation_kwargs\": {\"max_new_tokens\": 350}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pa7f7EzjtBXw"
   },
   "outputs": [],
   "source": [
    "print(results[\"llm\"][\"replies\"][0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "chromadb2",
   "language": "python",
   "name": "chromadb2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
