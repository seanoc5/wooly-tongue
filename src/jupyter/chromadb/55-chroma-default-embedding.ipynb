{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785e2592-56b4-4b65-ae9c-9de442b35538",
   "metadata": {},
   "source": [
    "# Chroma Default Embedding demo"
   ]
  },
  {
   "cell_type": "code",
   "id": "95f2fa97-c3f8-483e-a9f7-1215e37c4a30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:15:16.904479Z",
     "start_time": "2024-08-20T22:15:16.307298Z"
    }
   },
   "source": [
    "# started with https://ollama.com/blog/embedding-models  but have customized heavily since..\n",
    "\n",
    "import chromadb\n",
    "from rich import print  # https://rich.readthedocs.io/en/stable/markup.html#console-markup"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "a558659b-8c2a-4a1b-914f-e12ed829e5c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:15:16.954160Z",
     "start_time": "2024-08-20T22:15:16.951090Z"
    }
   },
   "source": [
    "documents = {\n",
    "    # vector db focus (level: easy)\n",
    "    'vdb1': \"Vector databases are a critical part of most LLM projects\",\n",
    "    'vdb2': \"Pinecone is a leading vendor of vector db services\",\n",
    "    'vdb3': \"ChromaDB is an opensource vector database (self-hosted) alternative to hosted services\",\n",
    "    'vdb4': \"A Document store is not a vector db, but offer a quick and easy alternative during development\",\n",
    "    \n",
    "    # embedding model focus (level: moderate)\n",
    "    'emb1': \"OpenAI is a  company leading in offering advanced llm services \",                                                                          # service (implicit embedding/vectors)\n",
    "    'emb2': \"There are three embedding models available from OpenAI: 'text-embedding-3-small', 'text-embedding-3-large', 'text-embedding-ada-002'.\",    #embedding model (implicit service)\n",
    "    'emb3': \"OpenAI's ada-002 was the previous de-facto standard, but it has been replaced with a more robust embedding model: text-embedding-3 (in 2 sizes)\", #embedding model \n",
    "    'emb4': \"text-embedding-3-small is likely the most appealing embedding model offered, with a balance of speed and accuracy.\",                       #embedding model (implicit service)\n",
    "    \n",
    "    # chunking (level: advanced)\n",
    "    'chu1': \"Chunking, or segementing, text is important in quality results from ML operations\",\n",
    "    'chu2': \"Splitting text into appropriate units is critical for LLMs\",\n",
    "    'chu3': \"Campbell's chunky soup is delicious, but not so healthy\",\n",
    "    \"chu4\": \"Separating text into chunks is a nuanced skill\",\n",
    "\n",
    "}\n",
    "\n",
    "questions = {\n",
    "    1:{'q':\"vector database\", 'cat':'vdb', 'ids':['vdb1','vdb2']},\n",
    "    2:{'q':'vector db', 'ids':['vdb1','vdb2']},\n",
    "    \n",
    "    3:{'q':'embedding', 'ids':['emb4', 'emb2']},\n",
    "    4:{'q':'embedding models', 'ids':['emb2', 'emb3']},\n",
    "    \n",
    "    \n",
    "    5:{'q':'chunking', 'ids':['chu1', 'chu2']},\n",
    "    6:{'q':'segmenting', 'ids':['chu1', 'chu2']},\n",
    "    # 7:{'q':'How long do animals live?', 'ids':[7,5]},\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e7afc092-1cb8-42eb-893e-ed22587931b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:15:17.104202Z",
     "start_time": "2024-08-20T22:15:17.028031Z"
    }
   },
   "source": [
    "client = chromadb.Client()\n",
    "\n",
    "collections = client.list_collections()\n",
    "print(f\"Collections: {collections}\")\n",
    "\n",
    "col_name = 'test-collection'\n",
    "if col_name in [c.name for c in client.list_collections()]:\n",
    "    collection = client.get_collection(name=col_name) # Get a collection object from an existing collection, by name. Will raise an exception if it's not found.\n",
    "    print(f\"[green]Found collection: {collection}[/], delete it so we can recreate fresh...\")\n",
    "    client.delete_collection(name=col_name)\n",
    "else:\n",
    "    print(f\"Collection does not already exist:{col_name}\")\n",
    "\n",
    "print(f\"[blue](re)Create collection: {col_name}, now...[/]\")\n",
    "collection = client.create_collection(name=col_name)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collections: \u001B[1m[\u001B[0m\u001B[1m]\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Collections: <span style=\"font-weight: bold\">[]</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Collection does not already exist:test-collection\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Collection does not already exist:test-collection\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1;34m(\u001B[0m\u001B[34mre\u001B[0m\u001B[1;34m)\u001B[0m\u001B[34mCreate collection: test-collection, now\u001B[0m\u001B[34m...\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">re</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span><span style=\"color: #000080; text-decoration-color: #000080\">Create collection: test-collection, now...</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "93d505e3-73be-4e02-95cc-7101e130bedf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:15:17.175023Z",
     "start_time": "2024-08-20T22:15:17.171918Z"
    }
   },
   "source": [
    "collection\n",
    "collection.get()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "30a64481-f37e-498d-ab10-a073fde680e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:15:19.477505Z",
     "start_time": "2024-08-20T22:15:17.218745Z"
    }
   },
   "source": [
    "# store each document in a vector embedding database\n",
    "for i, id in enumerate(documents):\n",
    "    doc = documents[id]\n",
    "    # print(f\"{i}) add doc: {doc}\")\n",
    "    collection.add(\n",
    "        ids=[id],\n",
    "        documents=[doc]\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "d5bdadff-0772-4843-964e-abc0abae7c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:15:19.486916Z",
     "start_time": "2024-08-20T22:15:19.482642Z"
    }
   },
   "source": [
    "existing_count = collection.count()\n",
    "print(f\"existing doc count: {existing_count}\")\n",
    "ids = collection.get(include=[])\n",
    "print(f\"collection ids: {ids}\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "existing doc count: \u001B[1;36m12\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">existing doc count: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "collection ids: \u001B[1m{\u001B[0m\u001B[32m'ids'\u001B[0m: \u001B[1m[\u001B[0m\u001B[32m'chu1'\u001B[0m, \u001B[32m'chu2'\u001B[0m, \u001B[32m'chu3'\u001B[0m, \u001B[32m'chu4'\u001B[0m, \u001B[32m'emb1'\u001B[0m, \u001B[32m'emb2'\u001B[0m, \u001B[32m'emb3'\u001B[0m, \u001B[32m'emb4'\u001B[0m, \u001B[32m'vdb1'\u001B[0m, \u001B[32m'vdb2'\u001B[0m, \u001B[32m'vdb3'\u001B[0m, \n",
       "\u001B[32m'vdb4'\u001B[0m\u001B[1m]\u001B[0m, \u001B[32m'embeddings'\u001B[0m: \u001B[3;35mNone\u001B[0m, \u001B[32m'metadatas'\u001B[0m: \u001B[3;35mNone\u001B[0m, \u001B[32m'documents'\u001B[0m: \u001B[3;35mNone\u001B[0m, \u001B[32m'uris'\u001B[0m: \u001B[3;35mNone\u001B[0m, \u001B[32m'data'\u001B[0m: \u001B[3;35mNone\u001B[0m\u001B[1m}\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">collection ids: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'ids'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'chu1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chu2'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chu3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chu4'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'emb1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'emb2'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'emb3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'emb4'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'vdb1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'vdb2'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'vdb3'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'vdb4'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'embeddings'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'metadatas'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'documents'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'uris'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "6c561ef0-713a-4fcf-839b-a8dffc37dcac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:15:19.530335Z",
     "start_time": "2024-08-20T22:15:19.527695Z"
    }
   },
   "source": [
    "# note: if tweaking table output, you likely want to re-run this cell along with the next, otherwise `rich` just appends to the existing table\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "table = Table(title=\"Simple Semantic Search Results\", show_lines=True)\n",
    "table.add_column(\"#\" )  # no_wrap=True\n",
    "table.add_column(\"Status\" )  # no_wrap=True\n",
    "table.add_column(\"Content\")  # no_wrap=True\n",
    "table.add_column(\"Score\" )\n",
    "\n",
    "style_good = 'green'\n",
    "style_failed = 'red bold'\n",
    "style_info = 'bright_black'"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "aade8535-34cc-4835-bf40-b9bf7ace86e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:15:19.642391Z",
     "start_time": "2024-08-20T22:15:19.573069Z"
    }
   },
   "source": [
    "# print(f\"\\nready for queries on collection: {col_name}\")\n",
    "for q_number in questions:\n",
    "    prompt = questions[q_number]['q']\n",
    "    expected_ids = questions[q_number]['ids']\n",
    "    table.add_row(f\"{q_number})\",  f\"QUESTION\", f\"{prompt}\", style='navy_blue on grey84 bold')\n",
    "    # use default collection embedding function for the prompt and retrieve the most relevant doc\n",
    "    results = collection.query(\n",
    "        query_texts=[prompt],\n",
    "        n_results=3\n",
    "    )\n",
    "\n",
    "    answers = results[\"documents\"][0]\n",
    "    for i, answer in enumerate(answers):\n",
    "        id = results[\"ids\"][0][i]\n",
    "        distance = results[\"distances\"][0][i]\n",
    "        if(i < len(expected_ids)):\n",
    "            expected = expected_ids[i]\n",
    "            if(id==expected):\n",
    "                # print(f\"\\t[green bold]got({id}):expected({expected}) (distance:{distance:.2f}): {answer}[/]\")\n",
    "                table.add_row('', f\"[{style_good}]got({id}) \\nexpected({expected})[/]\", f\"[{style_good}]{answer}[/]\",  f\"[{style_good}]{distance:.2f}\")\n",
    "            else:\n",
    "                table.add_row('', f\"[{style_failed}]got({id})[/] \\n[{style_info}]expected({expected})[/]\", f\"[{style_failed}]{answer}[/] \\n[{style_info}]{documents[expected]}[/]\" ,  f\"[{style_failed}]{distance:.2f}\")\n",
    "        else:\n",
    "            # table.add_row('', f\"[light_slate_grey](outside test)[/]\", f\"[light_slate_grey]{answer}[/]\", f\"{distance:.2f}\")\n",
    "            table.add_row('', '', f\"[{style_info}]{answer}[/]\", f\"{distance:.2f}\")\n",
    "\n",
    "console.print(table)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[3m                                          Simple Semantic Search Results                                           \u001B[0m\n",
       "┏━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m# \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mStatus        \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mContent                                                                          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mScore\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188m1)\u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188mQUESTION      \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188mvector database                                                                  \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188m     \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ \u001B[32mgot(vdb1) \u001B[0m     │ \u001B[32mVector databases are a critical part of most LLM projects\u001B[0m                         │ \u001B[32m0.49\u001B[0m  │\n",
       "│    │ \u001B[32mexpected(vdb1)\u001B[0m │                                                                                   │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ \u001B[1;31mgot(vdb4)\u001B[0m      │ \u001B[1;31mA Document store is not a vector db, but offer a quick and easy alternative \u001B[0m      │ \u001B[1;31m0.80\u001B[0m  │\n",
       "│    │ \u001B[90mexpected(vdb2)\u001B[0m │ \u001B[1;31mduring development\u001B[0m                                                                │       │\n",
       "│    │                │ \u001B[90mPinecone is a leading vendor of vector db services\u001B[0m                                │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │                │ \u001B[90mPinecone is a leading vendor of vector db services\u001B[0m                                │ 0.87  │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188m2)\u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188mQUESTION      \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188mvector db                                                                        \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188m     \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ \u001B[32mgot(vdb1) \u001B[0m     │ \u001B[32mVector databases are a critical part of most LLM projects\u001B[0m                         │ \u001B[32m0.63\u001B[0m  │\n",
       "│    │ \u001B[32mexpected(vdb1)\u001B[0m │                                                                                   │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ \u001B[1;31mgot(vdb4)\u001B[0m      │ \u001B[1;31mA Document store is not a vector db, but offer a quick and easy alternative \u001B[0m      │ \u001B[1;31m0.83\u001B[0m  │\n",
       "│    │ \u001B[90mexpected(vdb2)\u001B[0m │ \u001B[1;31mduring development\u001B[0m                                                                │       │\n",
       "│    │                │ \u001B[90mPinecone is a leading vendor of vector db services\u001B[0m                                │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │                │ \u001B[90mPinecone is a leading vendor of vector db services\u001B[0m                                │ 0.87  │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188m3)\u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188mQUESTION      \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188membedding                                                                        \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188m     \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ \u001B[32mgot(emb4) \u001B[0m     │ \u001B[32mtext-embedding-3-small is likely the most appealing embedding model offered, with\u001B[0m │ \u001B[32m0.81\u001B[0m  │\n",
       "│    │ \u001B[32mexpected(emb4)\u001B[0m │ \u001B[32ma balance of speed and accuracy.\u001B[0m                                                  │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ \u001B[32mgot(emb2) \u001B[0m     │ \u001B[32mThere are three embedding models available from OpenAI: 'text-embedding-3-small',\u001B[0m │ \u001B[32m0.99\u001B[0m  │\n",
       "│    │ \u001B[32mexpected(emb2)\u001B[0m │ \u001B[32m'text-embedding-3-large', 'text-embedding-ada-002'.\u001B[0m                               │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │                │ \u001B[90mOpenAI's ada-002 was the previous de-facto standard, but it has been replaced \u001B[0m    │ 1.02  │\n",
       "│    │                │ \u001B[90mwith a more robust embedding model: text-embedding-3 (in 2 sizes)\u001B[0m                 │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188m4)\u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188mQUESTION      \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188membedding models                                                                 \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188m     \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ \u001B[1;31mgot(emb4)\u001B[0m      │ \u001B[1;31mtext-embedding-3-small is likely the most appealing embedding model offered, with\u001B[0m │ \u001B[1;31m0.72\u001B[0m  │\n",
       "│    │ \u001B[90mexpected(emb2)\u001B[0m │ \u001B[1;31ma balance of speed and accuracy.\u001B[0m                                                  │       │\n",
       "│    │                │ \u001B[90mThere are three embedding models available from OpenAI: 'text-embedding-3-small',\u001B[0m │       │\n",
       "│    │                │ \u001B[90m'text-embedding-3-large', 'text-embedding-ada-002'.\u001B[0m                               │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ \u001B[1;31mgot(emb2)\u001B[0m      │ \u001B[1;31mThere are three embedding models available from OpenAI: 'text-embedding-3-small',\u001B[0m │ \u001B[1;31m0.84\u001B[0m  │\n",
       "│    │ \u001B[90mexpected(emb3)\u001B[0m │ \u001B[1;31m'text-embedding-3-large', 'text-embedding-ada-002'.\u001B[0m                               │       │\n",
       "│    │                │ \u001B[90mOpenAI's ada-002 was the previous de-facto standard, but it has been replaced \u001B[0m    │       │\n",
       "│    │                │ \u001B[90mwith a more robust embedding model: text-embedding-3 (in 2 sizes)\u001B[0m                 │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │                │ \u001B[90mOpenAI's ada-002 was the previous de-facto standard, but it has been replaced \u001B[0m    │ 0.98  │\n",
       "│    │                │ \u001B[90mwith a more robust embedding model: text-embedding-3 (in 2 sizes)\u001B[0m                 │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188m5)\u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188mQUESTION      \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188mchunking                                                                         \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188m     \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ \u001B[1;31mgot(chu4)\u001B[0m      │ \u001B[1;31mSeparating text into chunks is a nuanced skill\u001B[0m                                    │ \u001B[1;31m0.79\u001B[0m  │\n",
       "│    │ \u001B[90mexpected(chu1)\u001B[0m │ \u001B[90mChunking, or segementing, text is important in quality results from ML operations\u001B[0m │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ \u001B[1;31mgot(chu1)\u001B[0m      │ \u001B[1;31mChunking, or segementing, text is important in quality results from ML operations\u001B[0m │ \u001B[1;31m0.81\u001B[0m  │\n",
       "│    │ \u001B[90mexpected(chu2)\u001B[0m │ \u001B[90mSplitting text into appropriate units is critical for LLMs\u001B[0m                        │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │                │ \u001B[90mCampbell's chunky soup is delicious, but not so healthy\u001B[0m                           │ 1.27  │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188m6)\u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188mQUESTION      \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188msegmenting                                                                       \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\u001B[1;38;5;17;48;5;188m \u001B[0m\u001B[1;38;5;17;48;5;188m     \u001B[0m\u001B[1;38;5;17;48;5;188m \u001B[0m│\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ \u001B[32mgot(chu1) \u001B[0m     │ \u001B[32mChunking, or segementing, text is important in quality results from ML operations\u001B[0m │ \u001B[32m1.24\u001B[0m  │\n",
       "│    │ \u001B[32mexpected(chu1)\u001B[0m │                                                                                   │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ \u001B[1;31mgot(chu4)\u001B[0m      │ \u001B[1;31mSeparating text into chunks is a nuanced skill\u001B[0m                                    │ \u001B[1;31m1.33\u001B[0m  │\n",
       "│    │ \u001B[90mexpected(chu2)\u001B[0m │ \u001B[90mSplitting text into appropriate units is critical for LLMs\u001B[0m                        │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │                │ \u001B[90mSplitting text into appropriate units is critical for LLMs\u001B[0m                        │ 1.53  │\n",
       "└────┴────────────────┴───────────────────────────────────────────────────────────────────────────────────┴───────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                          Simple Semantic Search Results                                           </span>\n",
       "┏━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> #  </span>┃<span style=\"font-weight: bold\"> Status         </span>┃<span style=\"font-weight: bold\"> Content                                                                           </span>┃<span style=\"font-weight: bold\"> Score </span>┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> 1) </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> QUESTION       </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> vector database                                                                   </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\">       </span>│\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ <span style=\"color: #008000; text-decoration-color: #008000\">got(vdb1) </span>     │ <span style=\"color: #008000; text-decoration-color: #008000\">Vector databases are a critical part of most LLM projects</span>                         │ <span style=\"color: #008000; text-decoration-color: #008000\">0.49</span>  │\n",
       "│    │ <span style=\"color: #008000; text-decoration-color: #008000\">expected(vdb1)</span> │                                                                                   │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">got(vdb4)</span>      │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">A Document store is not a vector db, but offer a quick and easy alternative </span>      │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.80</span>  │\n",
       "│    │ <span style=\"color: #808080; text-decoration-color: #808080\">expected(vdb2)</span> │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">during development</span>                                                                │       │\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">Pinecone is a leading vendor of vector db services</span>                                │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">Pinecone is a leading vendor of vector db services</span>                                │ 0.87  │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> 2) </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> QUESTION       </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> vector db                                                                         </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\">       </span>│\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ <span style=\"color: #008000; text-decoration-color: #008000\">got(vdb1) </span>     │ <span style=\"color: #008000; text-decoration-color: #008000\">Vector databases are a critical part of most LLM projects</span>                         │ <span style=\"color: #008000; text-decoration-color: #008000\">0.63</span>  │\n",
       "│    │ <span style=\"color: #008000; text-decoration-color: #008000\">expected(vdb1)</span> │                                                                                   │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">got(vdb4)</span>      │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">A Document store is not a vector db, but offer a quick and easy alternative </span>      │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.83</span>  │\n",
       "│    │ <span style=\"color: #808080; text-decoration-color: #808080\">expected(vdb2)</span> │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">during development</span>                                                                │       │\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">Pinecone is a leading vendor of vector db services</span>                                │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">Pinecone is a leading vendor of vector db services</span>                                │ 0.87  │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> 3) </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> QUESTION       </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> embedding                                                                         </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\">       </span>│\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ <span style=\"color: #008000; text-decoration-color: #008000\">got(emb4) </span>     │ <span style=\"color: #008000; text-decoration-color: #008000\">text-embedding-3-small is likely the most appealing embedding model offered, with</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">0.81</span>  │\n",
       "│    │ <span style=\"color: #008000; text-decoration-color: #008000\">expected(emb4)</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">a balance of speed and accuracy.</span>                                                  │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ <span style=\"color: #008000; text-decoration-color: #008000\">got(emb2) </span>     │ <span style=\"color: #008000; text-decoration-color: #008000\">There are three embedding models available from OpenAI: 'text-embedding-3-small',</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">0.99</span>  │\n",
       "│    │ <span style=\"color: #008000; text-decoration-color: #008000\">expected(emb2)</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">'text-embedding-3-large', 'text-embedding-ada-002'.</span>                               │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">OpenAI's ada-002 was the previous de-facto standard, but it has been replaced </span>    │ 1.02  │\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">with a more robust embedding model: text-embedding-3 (in 2 sizes)</span>                 │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> 4) </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> QUESTION       </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> embedding models                                                                  </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\">       </span>│\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">got(emb4)</span>      │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">text-embedding-3-small is likely the most appealing embedding model offered, with</span> │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.72</span>  │\n",
       "│    │ <span style=\"color: #808080; text-decoration-color: #808080\">expected(emb2)</span> │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">a balance of speed and accuracy.</span>                                                  │       │\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">There are three embedding models available from OpenAI: 'text-embedding-3-small',</span> │       │\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">'text-embedding-3-large', 'text-embedding-ada-002'.</span>                               │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">got(emb2)</span>      │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">There are three embedding models available from OpenAI: 'text-embedding-3-small',</span> │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.84</span>  │\n",
       "│    │ <span style=\"color: #808080; text-decoration-color: #808080\">expected(emb3)</span> │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'text-embedding-3-large', 'text-embedding-ada-002'.</span>                               │       │\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">OpenAI's ada-002 was the previous de-facto standard, but it has been replaced </span>    │       │\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">with a more robust embedding model: text-embedding-3 (in 2 sizes)</span>                 │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">OpenAI's ada-002 was the previous de-facto standard, but it has been replaced </span>    │ 0.98  │\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">with a more robust embedding model: text-embedding-3 (in 2 sizes)</span>                 │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> 5) </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> QUESTION       </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> chunking                                                                          </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\">       </span>│\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">got(chu4)</span>      │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Separating text into chunks is a nuanced skill</span>                                    │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.79</span>  │\n",
       "│    │ <span style=\"color: #808080; text-decoration-color: #808080\">expected(chu1)</span> │ <span style=\"color: #808080; text-decoration-color: #808080\">Chunking, or segementing, text is important in quality results from ML operations</span> │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">got(chu1)</span>      │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Chunking, or segementing, text is important in quality results from ML operations</span> │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.81</span>  │\n",
       "│    │ <span style=\"color: #808080; text-decoration-color: #808080\">expected(chu2)</span> │ <span style=\"color: #808080; text-decoration-color: #808080\">Splitting text into appropriate units is critical for LLMs</span>                        │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">Campbell's chunky soup is delicious, but not so healthy</span>                           │ 1.27  │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> 6) </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> QUESTION       </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\"> segmenting                                                                        </span>│<span style=\"color: #00005f; text-decoration-color: #00005f; background-color: #d7d7d7; font-weight: bold\">       </span>│\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ <span style=\"color: #008000; text-decoration-color: #008000\">got(chu1) </span>     │ <span style=\"color: #008000; text-decoration-color: #008000\">Chunking, or segementing, text is important in quality results from ML operations</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">1.24</span>  │\n",
       "│    │ <span style=\"color: #008000; text-decoration-color: #008000\">expected(chu1)</span> │                                                                                   │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">got(chu4)</span>      │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Separating text into chunks is a nuanced skill</span>                                    │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1.33</span>  │\n",
       "│    │ <span style=\"color: #808080; text-decoration-color: #808080\">expected(chu2)</span> │ <span style=\"color: #808080; text-decoration-color: #808080\">Splitting text into appropriate units is critical for LLMs</span>                        │       │\n",
       "├────┼────────────────┼───────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
       "│    │                │ <span style=\"color: #808080; text-decoration-color: #808080\">Splitting text into appropriate units is critical for LLMs</span>                        │ 1.53  │\n",
       "└────┴────────────────┴───────────────────────────────────────────────────────────────────────────────────┴───────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "d0aaaf8b-f179-429e-96f7-533b514b4a0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:15:19.651662Z",
     "start_time": "2024-08-20T22:15:19.649501Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wt2",
   "language": "python",
   "name": "wt2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
