{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Sample code from haystack site:\n",
    "https://docs.haystack.deepset.ai/reference/integrations-pgvector"
   ],
   "id": "1cfe9caa7d9b62c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T21:54:04.333162Z",
     "start_time": "2024-09-17T21:54:02.919584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from haystack.utils import ComponentDevice\n",
    "from haystack import Document, Pipeline\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder, SentenceTransformersDocumentEmbedder\n",
    "\n",
    "from haystack_integrations.document_stores.pgvector import PgvectorDocumentStore\n",
    "from haystack_integrations.components.retrievers.pgvector import PgvectorEmbeddingRetriever\n",
    "\n",
    "import os\n",
    "import torch\n",
    "os.environ['PG_CONN_STR'] = \"postgresql://sean:pass1234@localhost:5432/vectors\"\n",
    "device = ComponentDevice.from_str(\"cuda:0\")\n",
    "print(f\"Device: {device}\")\n",
    "torch.cuda.is_available()\n",
    "# Set an environment variable `PG_CONN_STR` with the connection string to your PostgreSQL database.\n",
    "# e.g., \"postgresql://USER:PASSWORD@HOST:PORT/DB_NAME\""
   ],
   "id": "91199fc01fa414a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: ComponentDevice(_single_device=Device(type=<DeviceType.GPU: 'cuda'>, id=0), _multiple_devices=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from haystack import Document\n",
    "# from haystack import Pipeline\n",
    "# from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "# from haystack.components.embedders import SentenceTransformersTextEmbedder, SentenceTransformersDocumentEmbedder\n",
    "# from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "#\n",
    "# document_store = InMemoryDocumentStore(embedding_similarity_function=\"cosine\")\n",
    "#\n",
    "# documents = [Document(content=\"My name is Wolfgang and I live in Berlin\"),\n",
    "#              Document(content=\"I saw a black horse running\"),\n",
    "#              Document(content=\"Germany has many big cities\")]\n",
    "# document_embedder = SentenceTransformersDocumentEmbedder()\n",
    "# document_embedder.warm_up()\n",
    "# documents_with_embeddings = document_embedder.run(documents)['documents']\n",
    "# document_store.write_documents(documents_with_embeddings)\n",
    "# query_pipeline = Pipeline()\n",
    "# query_pipeline.add_component(\"text_embedder\", SentenceTransformersTextEmbedder())\n",
    "# query_pipeline.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store))\n",
    "# query_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "#\n",
    "# query = \"Who lives in Berlin?\"\n",
    "#\n",
    "# result = query_pipeline.run({\"text_embedder\":{\"text\": query}})\n",
    "#\n",
    "# print(result['retriever']['documents'][0])\n",
    "# Document(id=..., mimetype: 'text/plain',\n",
    "#  text: 'My name is Wolfgang and I live in Berlin')\n"
   ],
   "id": "1188f54f821a4c85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T21:54:09.638909Z",
     "start_time": "2024-09-17T21:54:09.636525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "document_store = PgvectorDocumentStore(\n",
    "    embedding_dimension=768,\n",
    "    vector_function=\"cosine_similarity\",\n",
    "    recreate_table=True,\n",
    ")\n",
    "\n",
    "documents = [Document(content=\"There are over 7,000 languages spoken around the world today.\"),\n",
    "             Document(content=\"Elephants have been observed to behave in a way that indicates...\"),\n",
    "             Document(content=\"In certain places, you can witness the phenomenon of bioluminescent waves.\")]"
   ],
   "id": "d3cf6ae1e215d7c2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T22:07:57.892024Z",
     "start_time": "2024-09-17T22:07:57.887123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from haystack.utils import Secret\n",
    "\n",
    "document_embedder = SentenceTransformersDocumentEmbedder(token=Secret.from_token(\"<<REPLACEME>>\"))\n",
    "# document_embedder = SentenceTransformersDocumentEmbedder()"
   ],
   "id": "e4b49c1a8bbb99f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T22:08:01.680731Z",
     "start_time": "2024-09-17T22:08:01.653246Z"
    }
   },
   "cell_type": "code",
   "source": "document_embedder.warm_up()",
   "id": "78323aa3603aa6cd",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SentenceTransformer.__init__() got an unexpected keyword argument 'model_kwargs'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdocument_embedder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwarm_up\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/wt2/lib/python3.10/site-packages/haystack/components/embedders/sentence_transformers_document_embedder.py:181\u001B[0m, in \u001B[0;36mSentenceTransformersDocumentEmbedder.warm_up\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;124;03mInitializes the component.\u001B[39;00m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 181\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_backend \u001B[38;5;241m=\u001B[39m \u001B[43m_SentenceTransformersEmbeddingBackendFactory\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_embedding_backend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_torch_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m        \u001B[49m\u001B[43mauth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtruncate_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtruncate_dim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/wt2/lib/python3.10/site-packages/haystack/components/embedders/backends/sentence_transformers_backend.py:37\u001B[0m, in \u001B[0;36m_SentenceTransformersEmbeddingBackendFactory.get_embedding_backend\u001B[0;34m(model, device, auth_token, trust_remote_code, truncate_dim, model_kwargs, tokenizer_kwargs)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m embedding_backend_id \u001B[38;5;129;01min\u001B[39;00m _SentenceTransformersEmbeddingBackendFactory\u001B[38;5;241m.\u001B[39m_instances:\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _SentenceTransformersEmbeddingBackendFactory\u001B[38;5;241m.\u001B[39m_instances[embedding_backend_id]\n\u001B[0;32m---> 37\u001B[0m embedding_backend \u001B[38;5;241m=\u001B[39m \u001B[43m_SentenceTransformersEmbeddingBackend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtruncate_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncate_dim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m _SentenceTransformersEmbeddingBackendFactory\u001B[38;5;241m.\u001B[39m_instances[embedding_backend_id] \u001B[38;5;241m=\u001B[39m embedding_backend\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m embedding_backend\n",
      "File \u001B[0;32m~/miniforge3/envs/wt2/lib/python3.10/site-packages/haystack/components/embedders/backends/sentence_transformers_backend.py:66\u001B[0m, in \u001B[0;36m_SentenceTransformersEmbeddingBackend.__init__\u001B[0;34m(self, model, device, auth_token, trust_remote_code, truncate_dim, model_kwargs, tokenizer_kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     57\u001B[0m     model: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     63\u001B[0m     tokenizer_kwargs: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, Any]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     64\u001B[0m ):\n\u001B[1;32m     65\u001B[0m     sentence_transformers_import\u001B[38;5;241m.\u001B[39mcheck()\n\u001B[0;32m---> 66\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mSentenceTransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth_token\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresolve_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mauth_token\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtruncate_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncate_dim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: SentenceTransformer.__init__() got an unexpected keyword argument 'model_kwargs'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T21:54:35.973974Z",
     "start_time": "2024-09-17T21:54:35.953013Z"
    }
   },
   "cell_type": "code",
   "source": "documents_with_embeddings = document_embedder.run(documents)",
   "id": "582a504d2ae26da6",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The embedding model has not been loaded. Please call warm_up() before running.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m documents_with_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mdocument_embedder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/wt2/lib/python3.10/site-packages/haystack/components/embedders/sentence_transformers_document_embedder.py:209\u001B[0m, in \u001B[0;36mSentenceTransformersDocumentEmbedder.run\u001B[0;34m(self, documents)\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    205\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSentenceTransformersDocumentEmbedder expects a list of Documents as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    206\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn case you want to embed a list of strings, please use the SentenceTransformersTextEmbedder.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    207\u001B[0m     )\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 209\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe embedding model has not been loaded. Please call warm_up() before running.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    211\u001B[0m texts_to_embed \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The embedding model has not been loaded. Please call warm_up() before running."
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T21:51:05.051399Z",
     "start_time": "2024-09-17T21:51:05.032551Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SentenceTransformer.__init__() got an unexpected keyword argument 'model_kwargs'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 12\u001B[0m\n\u001B[1;32m      7\u001B[0m documents \u001B[38;5;241m=\u001B[39m [Document(content\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere are over 7,000 languages spoken around the world today.\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m      8\u001B[0m              Document(content\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mElephants have been observed to behave in a way that indicates...\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m      9\u001B[0m              Document(content\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn certain places, you can witness the phenomenon of bioluminescent waves.\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\n\u001B[1;32m     11\u001B[0m document_embedder \u001B[38;5;241m=\u001B[39m SentenceTransformersDocumentEmbedder()\n\u001B[0;32m---> 12\u001B[0m \u001B[43mdocument_embedder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwarm_up\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m documents_with_embeddings \u001B[38;5;241m=\u001B[39m document_embedder\u001B[38;5;241m.\u001B[39mrun(documents)\n\u001B[1;32m     15\u001B[0m document_store\u001B[38;5;241m.\u001B[39mwrite_documents(documents_with_embeddings\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocuments\u001B[39m\u001B[38;5;124m\"\u001B[39m), policy\u001B[38;5;241m=\u001B[39mDuplicatePolicy\u001B[38;5;241m.\u001B[39mOVERWRITE)\n",
      "File \u001B[0;32m~/miniforge3/envs/wt2/lib/python3.10/site-packages/haystack/components/embedders/sentence_transformers_document_embedder.py:181\u001B[0m, in \u001B[0;36mSentenceTransformersDocumentEmbedder.warm_up\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;124;03mInitializes the component.\u001B[39;00m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 181\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_backend \u001B[38;5;241m=\u001B[39m \u001B[43m_SentenceTransformersEmbeddingBackendFactory\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_embedding_backend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_torch_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m        \u001B[49m\u001B[43mauth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtruncate_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtruncate_dim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/wt2/lib/python3.10/site-packages/haystack/components/embedders/backends/sentence_transformers_backend.py:37\u001B[0m, in \u001B[0;36m_SentenceTransformersEmbeddingBackendFactory.get_embedding_backend\u001B[0;34m(model, device, auth_token, trust_remote_code, truncate_dim, model_kwargs, tokenizer_kwargs)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m embedding_backend_id \u001B[38;5;129;01min\u001B[39;00m _SentenceTransformersEmbeddingBackendFactory\u001B[38;5;241m.\u001B[39m_instances:\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _SentenceTransformersEmbeddingBackendFactory\u001B[38;5;241m.\u001B[39m_instances[embedding_backend_id]\n\u001B[0;32m---> 37\u001B[0m embedding_backend \u001B[38;5;241m=\u001B[39m \u001B[43m_SentenceTransformersEmbeddingBackend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtruncate_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncate_dim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m _SentenceTransformersEmbeddingBackendFactory\u001B[38;5;241m.\u001B[39m_instances[embedding_backend_id] \u001B[38;5;241m=\u001B[39m embedding_backend\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m embedding_backend\n",
      "File \u001B[0;32m~/miniforge3/envs/wt2/lib/python3.10/site-packages/haystack/components/embedders/backends/sentence_transformers_backend.py:66\u001B[0m, in \u001B[0;36m_SentenceTransformersEmbeddingBackend.__init__\u001B[0;34m(self, model, device, auth_token, trust_remote_code, truncate_dim, model_kwargs, tokenizer_kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     57\u001B[0m     model: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     63\u001B[0m     tokenizer_kwargs: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, Any]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     64\u001B[0m ):\n\u001B[1;32m     65\u001B[0m     sentence_transformers_import\u001B[38;5;241m.\u001B[39mcheck()\n\u001B[0;32m---> 66\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mSentenceTransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth_token\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresolve_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mauth_token\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtruncate_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncate_dim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: SentenceTransformer.__init__() got an unexpected keyword argument 'model_kwargs'"
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "\n",
    "document_store.write_documents(documents_with_embeddings.get(\"documents\"), policy=DuplicatePolicy.OVERWRITE)"
   ],
   "id": "2f3cff3e4f58bfcd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "query_pipeline = Pipeline()\n",
    "query_pipeline.add_component(\"text_embedder\", SentenceTransformersTextEmbedder())\n",
    "query_pipeline.add_component(\"retriever\", PgvectorEmbeddingRetriever(document_store=document_store))\n",
    "query_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "\n",
    "query = \"How many languages are there?\"\n",
    "\n",
    "res = query_pipeline.run({\"text_embedder\": {\"text\": query}})\n",
    "\n",
    "assert res['retriever']['documents'][0].content == \"There are over 7,000 languages spoken around the world today.\"\n"
   ],
   "id": "62842e5740ff5098"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
