{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76664f2c",
   "metadata": {
    "id": "76664f2c"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/usecases/10k_sub_question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67904b-5fd6-443f-bf10-d49a69b25fcd",
   "metadata": {
    "id": "0f67904b-5fd6-443f-bf10-d49a69b25fcd"
   },
   "source": [
    "# 10K Analysis\n",
    "In this demo, we explore answering complex queries by decomposing them into simpler sub-queries.\n",
    "https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/usecases/10k_sub_question.ipynb#scrollTo=edd4bbb7-eef9-4b53-b05d-f91033635ac2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288c1af",
   "metadata": {
    "id": "f288c1af"
   },
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex 🦙."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfc3c897",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "cfc3c897",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5d863231-8331-490a-f2ef-9c43211f4d66",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-openai\n",
      "  Downloading llama_index_llms_openai-0.1.15-py3-none-any.whl.metadata (559 bytes)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.24 (from llama-index-llms-openai)\n",
      "  Downloading llama_index_core-0.10.28-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.1)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n",
      "  Downloading SQLAlchemy-2.0.29-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.9.3)\n",
      "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.2.14)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.2.0)\n",
      "Requirement already satisfied: httpx in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.27.0)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.16 (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n",
      "  Downloading llamaindex_py_client-0.1.17-py3-none-any.whl.metadata (760 bytes)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.2.1)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.17.0)\n",
      "Requirement already satisfied: pandas in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.2.3)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n",
      "  Downloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.10.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: wrapt in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.14.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.7.0)\n",
      "Requirement already satisfied: anyio in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: click in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.1)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\n",
      "Downloading llama_index_llms_openai-0.1.15-py3-none-any.whl (10 kB)\n",
      "Downloading llama_index_core-0.10.28-py3-none-any.whl (15.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.4/15.4 MB\u001B[0m \u001B[31m14.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading llamaindex_py_client-0.1.17-py3-none-any.whl (132 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m132.8/132.8 kB\u001B[0m \u001B[31m13.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m9.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading SQLAlchemy-2.0.29-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.2/3.2 MB\u001B[0m \u001B[31m15.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m11.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (620 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m620.0/620.0 kB\u001B[0m \u001B[31m16.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.4/49.4 kB\u001B[0m \u001B[31m9.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: dirtyjson, nltk, mypy-extensions, marshmallow, greenlet, typing-inspect, tiktoken, SQLAlchemy, llamaindex-py-client, dataclasses-json, llama-index-core, llama-index-llms-openai\n",
      "Successfully installed SQLAlchemy-2.0.29 dataclasses-json-0.6.4 dirtyjson-1.0.8 greenlet-3.0.3 llama-index-core-0.10.28 llama-index-llms-openai-0.1.15 llamaindex-py-client-0.1.17 marshmallow-3.21.1 mypy-extensions-1.0.0 nltk-3.8.1 tiktoken-0.6.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9828e56d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "9828e56d",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "59f1d0c7-9c3d-45e4-c9cf-b317ea699b67",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.10.28-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.2.2-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_cli-0.1.11-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.28 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index) (0.10.28)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.1.7-py3-none-any.whl.metadata (603 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index) (0.1.15)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.1.5-py3-none-any.whl.metadata (715 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.1.16-py3-none-any.whl.metadata (934 bytes)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: openai>=1.14.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.17.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (2024.2.0)\n",
      "Requirement already satisfied: httpx in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.16 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.1.17)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.14.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading PyMuPDF-1.24.1-cp311-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading llama_parse-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.9.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.7.0)\n",
      "Requirement already satisfied: anyio in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.9.0)\n",
      "Collecting PyMuPDFb==1.24.1 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading PyMuPDFb-1.24.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.28->llama-index) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.28->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/sean/mambaforge/envs/nvidia-test/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.16.0)\n",
      "Downloading llama_index-0.10.28-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_index_agent_openai-0.2.2-py3-none-any.whl (12 kB)\n",
      "Downloading llama_index_cli-0.1.11-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_embeddings_openai-0.1.7-py3-none-any.whl (6.0 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl (6.7 kB)\n",
      "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m9.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl (5.8 kB)\n",
      "Downloading llama_index_program_openai-0.1.5-py3-none-any.whl (4.1 kB)\n",
      "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.16-py3-none-any.whl (36 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading llama_parse-0.4.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading PyMuPDF-1.24.1-cp311-none-manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.9/3.9 MB\u001B[0m \u001B[31m15.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading PyMuPDFb-1.24.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m30.8/30.8 MB\u001B[0m \u001B[31m15.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m290.4/290.4 kB\u001B[0m \u001B[31m18.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: striprtf, pypdf, PyMuPDFb, pymupdf, llama-index-legacy, llama-parse, llama-index-readers-file, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed PyMuPDFb-1.24.1 llama-index-0.10.28 llama-index-agent-openai-0.2.2 llama-index-cli-0.1.11 llama-index-embeddings-openai-0.1.7 llama-index-indices-managed-llama-cloud-0.1.5 llama-index-legacy-0.9.48 llama-index-multi-modal-llms-openai-0.1.5 llama-index-program-openai-0.1.5 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.16 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.0 pymupdf-1.24.1 pypdf-4.2.0 striprtf-0.0.26\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf1e9b6-0f51-49df-a11d-50ba6a014f4d",
   "metadata": {
    "collapsed": true,
    "id": "cdf1e9b6-0f51-49df-a11d-50ba6a014f4d",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fbec4c-1864-4d76-9dbf-3d213ba58fc8",
   "metadata": {
    "collapsed": true,
    "id": "09fbec4c-1864-4d76-9dbf-3d213ba58fc8",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c743f504-f28c-4802-89b6-ad152b74b0eb",
   "metadata": {
    "id": "c743f504-f28c-4802-89b6-ad152b74b0eb"
   },
   "source": [
    "## Configure LLM service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c052250",
   "metadata": {
    "collapsed": true,
    "id": "4c052250",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# from google.colab import userdata\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ec8b0a-d5fa-4f74-a2cc-5cc52e009bc6",
   "metadata": {
    "collapsed": true,
    "id": "c4ec8b0a-d5fa-4f74-a2cc-5cc52e009bc6",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = OpenAI(temperature=0.2, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c69f38a",
   "metadata": {
    "id": "8c69f38a"
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db55c79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "7db55c79",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e40b4081-e32f-48cf-b93a-d850279c8089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-10 17:35:06--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1880483 (1.8M) [application/octet-stream]\n",
      "Saving to: ‘data/10k/uber_2021.pdf’\n",
      "\n",
      "data/10k/uber_2021. 100%[===================>]   1.79M  8.60MB/s    in 0.2s    \n",
      "\n",
      "2024-04-10 17:35:07 (8.60 MB/s) - ‘data/10k/uber_2021.pdf’ saved [1880483/1880483]\n",
      "\n",
      "--2024-04-10 17:35:07--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/lyft_2021.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1440303 (1.4M) [application/octet-stream]\n",
      "Saving to: ‘data/10k/lyft_2021.pdf’\n",
      "\n",
      "data/10k/lyft_2021. 100%[===================>]   1.37M  6.90MB/s    in 0.2s    \n",
      "\n",
      "2024-04-10 17:35:07 (6.90 MB/s) - ‘data/10k/lyft_2021.pdf’ saved [1440303/1440303]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/10k/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf' -O 'data/10k/uber_2021.pdf'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/lyft_2021.pdf' -O 'data/10k/lyft_2021.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fddd07-ff4c-44d4-82af-64e2e416e853",
   "metadata": {
    "id": "71fddd07-ff4c-44d4-82af-64e2e416e853"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd0ba028-1e70-4164-8af1-5f1df0ea76a9",
   "metadata": {
    "collapsed": true,
    "id": "dd0ba028-1e70-4164-8af1-5f1df0ea76a9",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lyft_docs = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/10k/lyft_2021.pdf\"]\n",
    ").load_data()\n",
    "uber_docs = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/10k/uber_2021.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd122d0d-2da6-4f46-aa2a-8a0049ad8694",
   "metadata": {
    "id": "fd122d0d-2da6-4f46-aa2a-8a0049ad8694"
   },
   "source": [
    "## Build indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e0b6e4c-2255-42cf-be88-0fe75a945d85",
   "metadata": {
    "collapsed": true,
    "id": "1e0b6e4c-2255-42cf-be88-0fe75a945d85",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lyft_index = VectorStoreIndex.from_documents(lyft_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a606df9c-ed2d-46fb-943e-ac47d24ba412",
   "metadata": {
    "collapsed": true,
    "id": "a606df9c-ed2d-46fb-943e-ac47d24ba412",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "uber_index = VectorStoreIndex.from_documents(uber_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668dffa8-1eb3-4209-913a-ed7debe7bee8",
   "metadata": {
    "id": "668dffa8-1eb3-4209-913a-ed7debe7bee8"
   },
   "source": [
    "## Build query engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82466534-c3d8-4619-ab1b-4abcd05c8ba7",
   "metadata": {
    "collapsed": true,
    "id": "82466534-c3d8-4619-ab1b-4abcd05c8ba7",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff449977-2c7c-433f-b303-ff1d7b66c7b3",
   "metadata": {
    "collapsed": true,
    "id": "ff449977-2c7c-433f-b303-ff1d7b66c7b3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "uber_engine = uber_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8775650f-b164-478c-8129-9a8e6a0cdc97",
   "metadata": {
    "collapsed": true,
    "id": "8775650f-b164-478c-8129-9a8e6a0cdc97",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=lyft_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"lyft_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Lyft financials for year 2021\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=uber_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"uber_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Uber financials for year 2021\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "s_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981caf5-38bb-4d5e-9068-b4874c62bfc9",
   "metadata": {
    "id": "6981caf5-38bb-4d5e-9068-b4874c62bfc9"
   },
   "source": [
    "## Run queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edd4bbb7-eef9-4b53-b05d-f91033635ac2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "collapsed": true,
    "id": "edd4bbb7-eef9-4b53-b05d-f91033635ac2",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "da5b94f1-2ea4-46b3-8ece-e5f72da6c777"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 0.40724556020094416 seconds as it raised APIConnectionError: Connection error..\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 1.297048058525676 seconds as it raised APIConnectionError: Connection error..\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._chat in 3.43048696617729 seconds as it raised APIConnectionError: Connection error..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-7ff6a2c4f22d>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m response = s_engine.query(\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0;34m\"Compare and contrast the customer segments and geographies that grew the\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;34m\" fastest\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m )\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    272\u001B[0m             )\n\u001B[1;32m    273\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 274\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    275\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    276\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSpanDropEvent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspan_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mid_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_str\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/base/base_query_engine.py\u001B[0m in \u001B[0;36mquery\u001B[0;34m(self, str_or_query_bundle)\u001B[0m\n\u001B[1;32m     51\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr_or_query_bundle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m                 \u001B[0mstr_or_query_bundle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mQueryBundle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr_or_query_bundle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 53\u001B[0;31m             \u001B[0mquery_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_query\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr_or_query_bundle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     54\u001B[0m         \u001B[0mdispatch_event\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mQueryEndEvent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mquery_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/query_engine/sub_question_query_engine.py\u001B[0m in \u001B[0;36m_query\u001B[0;34m(self, query_bundle)\u001B[0m\n\u001B[1;32m    143\u001B[0m             \u001B[0mCBEventType\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mQUERY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpayload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mEventPayload\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mQUERY_STR\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mquery_bundle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquery_str\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m         ) as query_event:\n\u001B[0;32m--> 145\u001B[0;31m             \u001B[0msub_questions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_question_gen\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_metadatas\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquery_bundle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m             \u001B[0mcolors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_color_mapping\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msub_questions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/question_gen/openai/base.py\u001B[0m in \u001B[0;36mgenerate\u001B[0;34m(self, tools, query)\u001B[0m\n\u001B[1;32m     86\u001B[0m         \u001B[0mquery_str\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mquery\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquery_str\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m         question_list = cast(\n\u001B[0;32m---> 88\u001B[0;31m             \u001B[0mSubQuestionList\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_program\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery_str\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mquery_str\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtools_str\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtools_str\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     89\u001B[0m         )\n\u001B[1;32m     90\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mquestion_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/program/openai/base.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, llm_kwargs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    170\u001B[0m         \u001B[0mmessages\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_prompt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat_messages\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mllm\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_llm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    171\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 172\u001B[0;31m         chat_response = self._llm.chat(\n\u001B[0m\u001B[1;32m    173\u001B[0m             \u001B[0mmessages\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmessages\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    174\u001B[0m             \u001B[0mtools\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mopenai_fn_spec\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/llms/callbacks.py\u001B[0m in \u001B[0;36mwrapped_llm_chat\u001B[0;34m(_self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    142\u001B[0m                     },\n\u001B[1;32m    143\u001B[0m                 )\n\u001B[0;32m--> 144\u001B[0;31m                 \u001B[0mf_return_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_self\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf_return_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mGenerator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/llms/openai/base.py\u001B[0m in \u001B[0;36mchat\u001B[0;34m(self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    294\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    295\u001B[0m             \u001B[0mchat_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompletion_to_chat_decorator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_complete\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 296\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mchat_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    298\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mllm_chat_callback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001B[0m in \u001B[0;36mwrapped_f\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    287\u001B[0m         \u001B[0;34m@\u001B[0m\u001B[0mfunctools\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwraps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    288\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mwrapped_f\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAny\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAny\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 289\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    290\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    291\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mretry_with\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAny\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mWrappedFn\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    387\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDoSleep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    388\u001B[0m                 \u001B[0mretry_state\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprepare_for_next_attempt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 389\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    390\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    391\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mdo\u001B[0m  \u001B[0;31m# type: ignore[no-any-return]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/nap.py\u001B[0m in \u001B[0;36msleep\u001B[0;34m(seconds)\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[0mThis\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mdefault\u001B[0m \u001B[0mstrategy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mmay\u001B[0m \u001B[0mbe\u001B[0m \u001B[0mmocked\u001B[0m \u001B[0mout\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0munit\u001B[0m \u001B[0mtesting\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m     \"\"\"\n\u001B[0;32m---> 31\u001B[0;31m     \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseconds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "response = s_engine.query(\n",
    "    \"Compare and contrast the customer segments and geographies that grew the\"\n",
    "    \" fastest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b631d68b-dd17-4afd-9ed7-da0131041c8b",
   "metadata": {
    "collapsed": true,
    "id": "b631d68b-dd17-4afd-9ed7-da0131041c8b",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "aff1a743-5a84-4276-92c4-bb7a34eec8d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uber and Lyft both experienced the fastest growth in their respective customer segments and geographies in 2021. \n",
      "\n",
      "For Uber, the fastest growing customer segments were Riders and Eaters, who use the platform for ridesharing services and meal preparation, grocery, and other delivery services, respectively. Additionally, Uber One, Uber Pass, Eats Pass, and Rides Pass membership programs grew significantly in 2021, with over 6 million members. Uber experienced the fastest growth in five metropolitan areas—Chicago, Miami, and New York City in the United States, Sao Paulo in Brazil, and London in the United Kingdom. Additionally, Uber experienced growth in suburban and rural areas, though the network is smaller and less liquid in these areas.\n",
      "\n",
      "For Lyft, the fastest growing customer segments were ridesharing, Express Drive, Lyft Rentals, Light Vehicles, Public Transit, and Lyft Autonomous. Lyft has grown rapidly in cities across the United States and in select cities in Canada. The ridesharing market grew rapidly prior to the COVID-19 pandemic, and it is uncertain to what extent market acceptance will continue to grow after the pandemic. The market for Lyft's other offerings, such as its network of Light Vehicles, is also new and unproven, and it is uncertain whether demand for bike and scooter sharing will continue to grow.\n",
      "\n",
      "Overall, Uber and Lyft experienced the fastest growth in different customer segments and geographies. Uber experienced the fastest growth in Riders and Eaters, as well as in five metropolitan areas, while Lyft experienced the fastest growth in ridesharing, Express Drive, Lyft Rentals, Light Vehicles, Public Transit, and Lyft Autonomous, as well as in cities across the United States and in select cities in Canada.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbbdd5b-0076-48c8-b233-e2ba43d7a6de",
   "metadata": {
    "collapsed": true,
    "id": "6bbbdd5b-0076-48c8-b233-e2ba43d7a6de",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2ae13d64-63d2-4628-d638-d728f137fff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2 sub questions.\n",
      "\u001B[36;1m\u001B[1;3m[uber_10k] Q: What is the revenue growth of Uber from 2020 to 2021\n",
      "\u001B[0m\u001B[33;1m\u001B[1;3m[lyft_10k] Q: What is the revenue growth of Lyft from 2020 to 2021\n",
      "\u001B[0m\u001B[33;1m\u001B[1;3m[lyft_10k] A: \n",
      "The revenue of Lyft grew by 36% from 2020 to 2021.\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m[uber_10k] A: \n",
      "The revenue growth of Uber from 2020 to 2021 was 57%, or 54% on a constant currency basis.\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "response = s_engine.query(\n",
    "    \"Compare revenue growth of Uber and Lyft from 2020 to 2021\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf421e-5938-4031-81df-cfbfd347b674",
   "metadata": {
    "collapsed": true,
    "id": "fadf421e-5938-4031-81df-cfbfd347b674",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f24d3a6b-5a2d-4d47-bb53-3d8fcb0c3087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The revenue growth of Uber from 2020 to 2021 was 57%, or 54% on a constant currency basis, while the revenue of Lyft grew by 36% from 2020 to 2021. Therefore, Uber had a higher revenue growth than Lyft from 2020 to 2021.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
