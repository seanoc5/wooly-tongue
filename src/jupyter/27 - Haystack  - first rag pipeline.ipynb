{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c344997a-0d1e-4924-aaed-2b451d0036b5",
   "metadata": {},
   "source": [
    "# Haystack 27 - first rag pipeline\n",
    "\n",
    "https://github.com/deepset-ai/haystack-tutorials/blob/main/tutorials/27_First_RAG_Pipeline.ipynb\n",
    "\n",
    "**Note**: needed to `mamba install bitsandbytes accelerate`"
   ]
  },
  {
   "cell_type": "code",
   "id": "159cdb4e-df2f-41f7-9653-33ec11f86899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:30.174561Z",
     "start_time": "2024-04-22T20:33:29.228706Z"
    }
   },
   "source": [
    "from haystack.telemetry import tutorial_running\n",
    "\n",
    "tutorial_running(27)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "ead0a354-709b-43c4-8edb-1ab896c098a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:30.177124Z",
     "start_time": "2024-04-22T20:33:30.175307Z"
    }
   },
   "source": [
    "# from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "from haystack import Pipeline, PredefinedPipeline"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b145f600-2748-43af-9ce9-f0196807ab2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:30.215740Z",
     "start_time": "2024-04-22T20:33:30.177572Z"
    }
   },
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "83e331c7-a5f9-449c-91a5-ba105e42fa94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:32.479889Z",
     "start_time": "2024-04-22T20:33:30.216548Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "6a2efac1-96ae-48d3-b569-fc7ad184421b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:33.974245Z",
     "start_time": "2024-04-22T20:33:32.480646Z"
    }
   },
   "source": [
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_embedder.warm_up()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "47a57ff8-b38b-492e-8f11-95fc99108e5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:34.237588Z",
     "start_time": "2024-04-22T20:33:33.975055Z"
    }
   },
   "source": [
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4125b79f574f4491a80626aa268abfcc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "19bdaa95-9d05-4d74-a7c6-0191017e1dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:34.239618Z",
     "start_time": "2024-04-22T20:33:34.238058Z"
    }
   },
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "cc0d1c01-8b28-4060-8ad7-18a126348c02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:34.278481Z",
     "start_time": "2024-04-22T20:33:34.240025Z"
    }
   },
   "source": [
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "\n",
    "retriever = InMemoryEmbeddingRetriever(document_store)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "690a0ddb-9352-4802-98ef-25c2c851c8df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:34.285434Z",
     "start_time": "2024-04-22T20:33:34.279148Z"
    }
   },
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "template = \"\"\"\n",
    "Given the following information, answer the question.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=template)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "6bdafd1b-5ad7-42c2-b576-ae62a98f5f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:34.308581Z",
     "start_time": "2024-04-22T20:33:34.286874Z"
    }
   },
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import torch\n",
    "# from haystack.components.generators import OpenAIGenerator\n",
    "# from haystack.components.generators import \n",
    "from haystack.components.generators import HuggingFaceLocalGenerator\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key: \")\n",
    "# generator = OpenAIGenerator(model=\"gpt-3.5-turbo\")\n",
    "# generator = HuggingFaceLocalGenerator(\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "#                                  huggingface_pipeline_kwargs={\n",
    "#                                      # \"device_map\":\"auto\",\n",
    "#                                                \"model_kwargs\":{\"load_in_4bit\":True,\n",
    "#                                                 \"bnb_4bit_use_double_quant\":True,\n",
    "#                                                 \"bnb_4bit_quant_type\":\"nf4\",\n",
    "#                                                 \"bnb_4bit_compute_dtype\":torch.bfloat16}},\n",
    "#                                  generation_kwargs={\"max_new_tokens\": 350})\n",
    "\n",
    "# https://docs.haystack.deepset.ai/docs/huggingfacelocalgenerator\n",
    "generator = HuggingFaceLocalGenerator(model=\"google/flan-t5-large\",\n",
    "                                      task=\"text2text-generation\",\n",
    "                                      generation_kwargs={\n",
    "                                        \"max_new_tokens\": 400,\n",
    "                                        \"temperature\": 0.8,\n",
    "                                        })"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "23fea0fc-2b13-46a4-ba73-bed616939777",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:34.311318Z",
     "start_time": "2024-04-22T20:33:34.309046Z"
    }
   },
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "basic_rag_pipeline = Pipeline()\n",
    "# Add components to your pipeline\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"llm\", generator)\n",
    "\n",
    "# Now, connect the components to each other\n",
    "basic_rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "basic_rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "basic_rag_pipeline.connect(\"prompt_builder\", \"llm\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fc9040af910>\n",
       "ðŸš… Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: HuggingFaceLocalGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - text_embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "14d86079cc1c778e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:35.996839Z",
     "start_time": "2024-04-22T20:33:34.311717Z"
    }
   },
   "source": [
    "question = \"What does Rhodes Statue look like?\"\n",
    "\n",
    "response = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa72d987208c416195e1c4d1db820a8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2707 > 512). Running this sequence through the model will result in indexing errors\n",
      "/home/sean/miniforge3/envs/haystack/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:35.999116Z",
     "start_time": "2024-04-22T20:33:35.997381Z"
    }
   },
   "cell_type": "code",
   "source": "print(response[\"llm\"][\"replies\"][0])",
   "id": "0353c467-2ffa-404e-b725-db4dc726df0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a statue of Helios\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "18df0e54-baaa-4b1d-8c17-6c30664049ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:33:36.000520Z",
     "start_time": "2024-04-22T20:33:35.999544Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "haystack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
